{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "(1)_[colab_Youth]_Module_18_Model_outputs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vylGihzwmbXX"
      },
      "source": [
        "# Data Lesson Map\n",
        "\n",
        "<font color=red>Red </font> highlighted is the topic covered for this lesson\n",
        "\n",
        "1. <font color=red>Basics Data Science and Visualisation</font>\n",
        ">* <font color=red>Obtaining Data</font>\n",
        ">* Basic Data Processing\n",
        ">* Basic statistics\n",
        ">* <font color=red>Data visualization</font>\n",
        ">* Handling erroneous and missing data\n",
        "2. <font color=red>Data Machine Learning Techniques</font>\n",
        ">* <font color=red>Supervised Learning Techniques</font>\n",
        ">* Supervised Regression\n",
        ">* Artificial Neural Networks\n",
        "3. <font color=red>AI for Data Walkthrough </font>\n",
        ">* <font color=red>Model Output </font>\n",
        ">* Outputs Visualisation and Validation\n",
        "4. <font color=red>AI Models </font>\n",
        ">* Linear Regression\n",
        ">* <font color=red>Underfitting vs Overfitting</font>\n",
        ">* <font color=red>K-Nearest Neighbour (KNN)</font>\n",
        ">* <font color=red>Decision Tree</font>\n",
        ">* Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ipMvNZtt8R9"
      },
      "source": [
        "# Model Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMABKNLZt8SC"
      },
      "source": [
        "Previously, you have learnt how to train a model and how to use it for predictions. While that is essential in any data science project, it is not sufficient to just train a model and using it for predictions. This is because even though the model has been trained, we did not evaluate its performance. \n",
        "\n",
        "The model has to be evaluated against data that was not used to train the model. This is because while the model may perform very well with data that it has trained with, it may not be useful if the model is not able to be used for data that it was not trained with. Thus, in this notebook, we will also learn how to ensure that this does not happen. Before we do so, we have to first understand why a model can perform poorly to unseen data even after training. This could be due to either underfitting or overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aIGfNkq8Sen"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5w_3zLXt8SE"
      },
      "source": [
        "## 1. Underfitting vs Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369tFWSBt8SF"
      },
      "source": [
        "Underfitting means that the model is too simplified to be able to explain the data. For example, if you have data that has a non-linear relationship but you are using a linear model to train on, you may suffer from underfitting. This is because the linear model will not be able to explain the non-linear relationship or trend that is observed in the data. Thus, when you use an underfitted model to predict, it will perform poorly.\n",
        "\n",
        "On the other hand, overfitting means that the model is fitted so well that it has also learnt all the noise or outliers within the dataset. As such, it can perform very well when you test it against data that it has been trained with. However, because it is so well trained, it will not be able to generalise and thus, will not perform well when you are testing it against data that it was not trained with.\n",
        "\n",
        "Read this [article](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76) and this [article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229) for more information about underfitting and overfitting and note down any interesting information in the cell below. While there may be some mathematical equations within the articles, it is ok if you are not able to understand the equations. It is more important to understand the underlying concepts. What is the difference between bias and variance? How do you prevent underfitting? How do you prevent overfitting?\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlS0eENTt8SH"
      },
      "source": [
        "# Bias -> Bias is the difference between the average prediction of our model and the correct value which we are trying to predict.\n",
        "# variance -> Variance is the variability of model prediction for a given data point or a value which tells us spread of our data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNPqLwLQt8SL"
      },
      "source": [
        "Look at the figures below. If the red line were to be your model and the blue points are the dataset, would the model be overfitting or underfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZrPHjXz376l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_ENIQGVt8SN"
      },
      "source": [
        "![Underfitting](https://miro.medium.com/max/2688/1*khzX1tmUj86vfpzE6Gkf0A.png)\n",
        "\n",
        "Please refer to \n",
        "\"/content/Intel_AI4Y/My Drive/Intel_AI4Y_Colab/Module_18/resources/model1.jpg\"\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9WQU6pDt8SO"
      },
      "source": [
        "# overfitting "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztn9cFnMt8ST"
      },
      "source": [
        "![Overfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Overfitted_Data.png/300px-Overfitted_Data.png)\n",
        "\n",
        "Please refer to \n",
        "\"/content/Intel_AI4Y/My Drive/Intel_AI4Y_Colab/Module_18/resources/model2.jpg\"\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTeKLnMGt8SU"
      },
      "source": [
        "# underfitting "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8j9LA1Kt8SY"
      },
      "source": [
        "## 2. Balance between underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhlcHo2Ot8SZ"
      },
      "source": [
        "We can see from above that it is important to try and find a balance between underfitting and overfitting. This will allow the model to be accurate but still be able to generalise or perform well on data that it has not been trained in. This means that the model has to be somewhat complex but not too complex. As such, there are some ways that we can try to achieve the balance. We will try some of these methods for the different machine learning techniques that were explored earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpK_2XzOt8Sb"
      },
      "source": [
        "## 2.1 K-Nearest Neighbour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWvqc37Et8Se"
      },
      "source": [
        "In an earlier workshop, we learnt how to apply the K-Nearest Neighbour (KNN) algorithm to classify data. As a recap, KNN classifies data points based on the majority of the other points that are closest to the point in question. However, in order to use the algorithm, there was a need to input the number of neighbours as a parameter. In the case of underfitting and overfitting, the number of neighbours do play an important role. This is because the number of neighbours determine how likely the model will overfit. The higher the number of neighbours, the less likely the model will overfit. If the number of neighbours is too high, it will be likely for the model to underfit. Thus, there should be some number in between the two extreme numbers that will allow the model to be relatively balanced. This number will differ for different datasets. We will now try to find this number for the Iris Flower dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0dgl9gKt8Si"
      },
      "source": [
        "First, we will need to read in the Iris Flower dataset as a dataframe df from iris.data. Remember to check if the dataframe has column names and also perform the standard checks for the dataset (i.e check for erroneous data and outliers). You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below to understand the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7VbeSPFt8Sj"
      },
      "source": [
        "![alt text](https://www.researchgate.net/profile/Zhi-Gang_Zhao2/publication/272514310/figure/fig6/AS:340442961989646@1458179335869/Trollius-ranunculoide-flower-with-measured-traits.png)\n",
        "\n",
        "Please refer to \n",
        "\"/content/Intel_AI4Y/My Drive/Intel_AI4Y_Colab/Module_18/resources/PetalSepal1.png\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9APtyvGuaAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6c385b-652e-489c-b97a-192bc4afb59d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Intel_AI4Y')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Intel_AI4Y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9wgN3fh8NAJ"
      },
      "source": [
        "<font color=red>Hints:</font> \n",
        "\n",
        "*   Refer to Module 17 Assignment 1 \"Supervised_learning_techniques\"in the beginning or Module 17 Assignment 3 \"2. Obtain and explore dataset\"\n",
        "*   Remember to print head and describe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGHHTX4Rt8Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9657874-4ff4-44f8-b494-c9de4d3a9660"
      },
      "source": [
        "df = pd.read_csv('/content/Intel_AI4Y/My Drive/Intel_AI4Y/Students_E_Learning/Copy_To_Google_Drive/Intel_AI4Y_Colab/Module_18/data/iris.data')\n",
        "names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
        "\n",
        "df.columns = names\n",
        "df.info()\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149 entries, 0 to 148\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal length  149 non-null    float64\n",
            " 1   sepal width   149 non-null    float64\n",
            " 2   petal length  149 non-null    float64\n",
            " 3   petal width   149 non-null    float64\n",
            " 4   class         149 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 5.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ImARNVCrFFCF",
        "outputId": "8ea9ce93-91b2-4317-fad3-bdf42307c048"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>149.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>149.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.848322</td>\n",
              "      <td>3.051007</td>\n",
              "      <td>3.774497</td>\n",
              "      <td>1.205369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828594</td>\n",
              "      <td>0.433499</td>\n",
              "      <td>1.759651</td>\n",
              "      <td>0.761292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length  sepal width  petal length  petal width\n",
              "count    149.000000   149.000000    149.000000   149.000000\n",
              "mean       5.848322     3.051007      3.774497     1.205369\n",
              "std        0.828594     0.433499      1.759651     0.761292\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.400000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "UR0QxljXFSqF",
        "outputId": "94440cd0-a834-41af-e633-0d2dbeb708f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width        class\n",
              "0           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "1           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "2           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "3           5.0          3.6           1.4          0.2  Iris-setosa\n",
              "4           5.4          3.9           1.7          0.4  Iris-setosa"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou7x2iIwt8Sn"
      },
      "source": [
        "Now, perform the necessary steps that are required to prepare the data to be processed by a machine learning algroithm. First, extract the features as `x_values` and the target variable as `y_values`. In this case, the `x_values` will be \"`sepal_length`\", \"`sepal_width`\", \"`petal_length`\" and \"`petal_width`\" whereas the . Additionally, remmeber to label encode the y_values. You can encode \"`Setosa`\" as `0`, \"`Versicolor`\" as `1` and \"`Virginica`\" as `2`. Refer to earlier notebooks if you require a reference for the necessary codes.\n",
        "\n",
        "\n",
        "<font color=red>Hints:</font> \n",
        "*   refer to Module 17 assignment 1 \"Supervised_learning_techniques\" at \"Setting up data for the KNN algorithm\" section\n",
        "*   `x_values` => dataframe \"`sepal_length`\", \"`sepal_width`\", \"`petal_length`\" and \"`petal_width`\"\n",
        "*   `y_values` => dataframe \"class\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLhfg7w6t8So",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36fe946-f6c3-43de-852a-48538ed8d1ed"
      },
      "source": [
        "# encode y_values into numerical data\n",
        "label_encode_setosa = {\"class\": {\"Iris-setosa\":0}}\n",
        "label_encode_versicolor = {\"class\": {\"Iris-versicolor\":1}}\n",
        "label_encode_virginica = {\"class\": {\"Iris-virginica\":2}}\n",
        "\n",
        "df.replace(label_encode_setosa,inplace=True)\n",
        "df.replace(label_encode_versicolor,inplace=True)\n",
        "df.replace(label_encode_virginica,inplace=True)\n",
        "print(df['class'].value_counts())\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    50\n",
            "1    50\n",
            "0    49\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "cyDEYEayEjOF",
        "outputId": "890db76f-eaa5-4df9-bfd1-ce8049db6ee0"
      },
      "source": [
        "pd.get_dummies(df['class'])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  1  2\n",
              "0    1  0  0\n",
              "1    1  0  0\n",
              "2    1  0  0\n",
              "3    1  0  0\n",
              "4    1  0  0\n",
              "..  .. .. ..\n",
              "144  0  0  1\n",
              "145  0  0  1\n",
              "146  0  0  1\n",
              "147  0  0  1\n",
              "148  0  0  1\n",
              "\n",
              "[149 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B-SG4YYF6B_",
        "outputId": "12e385c7-8561-41a8-8746-4e5e084e6f29"
      },
      "source": [
        "x_values = df[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "y_values = df['class']\n",
        "\n",
        "print(x_values.head())\n",
        "print(y_values.head())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length  sepal width  petal length  petal width\n",
            "0           4.9          3.0           1.4          0.2\n",
            "1           4.7          3.2           1.3          0.2\n",
            "2           4.6          3.1           1.5          0.2\n",
            "3           5.0          3.6           1.4          0.2\n",
            "4           5.4          3.9           1.7          0.4\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RO3bT3Bt8Sr"
      },
      "source": [
        "After we are assurred that the data is ready to be processed by a machine learning technique, we can now focus on how to balance the overfitting and underfitting issue.\n",
        "\n",
        "If we want to determine this balance, we will need to be able to evaluate how well the model will perform or how accuracte the model will be if the model were to be applied to data that it has not been trained with. As we do not have future data, we will need to be able to use the current data to perform this evaluation. As such, the current dataset is usually split into 2 different groups. One group will contain all the training data which will be used to train the data. On the other hand, the other group will contain test data that will not be seen or used in the model training phase. The test data will serve as \"future\" data which will be used to evaluate the model.\n",
        "\n",
        "In order to split the data into 2 groups, we will use the `train_test_split` function from `sklearn.model_selection`. Try the code below to import the `train_test_split` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjnc2yD4t8Ss"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7U851Odt8Sv"
      },
      "source": [
        "Use the `train_test_split` function to split the data into the train group and the test group. The test group usually will contain 20% to 30% of the dataset. In this case, we can split the data based on 75% in the train group and 25% in the test group. Read this [article](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) to understand how to use the `train_test_split` function. You can create variables called `x_train`, `y_train`, `x_test` and `y_test` to hold the training and testing data. Additionally, you can also add a random_state to ensure that the data is always split the same way everytime you run the code.\n",
        "\n",
        "<font color=red>Hints:</font> \n",
        "*   Refer to Moudle 17 assignment 2 \"Supervised_Regression\"\n",
        "*   `test_size = 0.25`\n",
        "*   `random_state=10`\n",
        "*   Please review: https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuErkKoSt8Sx"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.25, random_state=10)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTCPDqgkt8S2"
      },
      "source": [
        "After splitting the data, we now have to standardise or normalise the data. It is always good practice to standardise or normalise any dataset that you use for machine learning. This will help scale the values for all the variables or features into similar ranges. Always remember to conduct the standardisation or normalisation after the data has been split. This is to ensure that the test dataset will always remain unseen by the model and not used in the normalisation or standardisation process of the training data.\n",
        "\n",
        "In this case, we will choose to use StandardScaler from `sklearn.preprocessing` to standardise the data. Remember to apply the `.fit_transform` method to the `x_train` data values but only the .transform method to the `x_test` data. Implement the standardisation process in the cell below. Create a variable called `x_train_scale` for the train data after standardisation and create another variable called `x_test` scale for the test data after standardisation.\n",
        "\n",
        "<font color=red>Hint:</font>  refer to Module 17 Assignment 3 \"Artificial_neural_networks\"  look for `StandardScaler()`, `standardise.fit_transform()` and `standardise.transform()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBSK_qYGt8S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec5156f-42e7-41e1-ce64-932cf822897c"
      },
      "source": [
        "# Proceed with standardisation\n",
        "print(\"Number of rows in x_train:\", x_train.shape[0])\n",
        "print(\"Number of rows in x_test:\", x_test.shape[0])\n",
        "print(\"Number of rows in y_train:\", y_train.shape[0])\n",
        "print(\"Number of rows in y_test:\", y_test.shape[0])\n",
        "\n",
        "standardise = StandardScaler()\n",
        "\n",
        "x_train_scale = standardise.fit_transform(x_train)\n",
        "x_test_scale = standardise.transform(x_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in x_train: 111\n",
            "Number of rows in x_test: 38\n",
            "Number of rows in y_train: 111\n",
            "Number of rows in y_test: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRx3htnyt8TB"
      },
      "source": [
        "After standardising the data, we can now implement a way to find the optimal number of neighbours for the KNN algorithm. To do so, we will train the KNN algorithm with differnt number of neighbours and also evaluate against the test data. By doing so, we will be able to obtain the accuracy of the KNN model for different number of neighbours. We can then find the number of neighbours that correspond to the highest accuracy. That number will be the optimal number of neighbours. Try the code below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfFP_-0Jt8TD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9131b5-2446-4a58-86a2-05350b1fd293"
      },
      "source": [
        "# Create an empty list to store the accuracy and number of neighbours for each KNN model\n",
        "accuracy = []\n",
        "num_neigh = []\n",
        "\n",
        "# Use ii to cycle through values 1 to 15. This will be the number of neighbours for the KNN classifier. \n",
        "for ii in range(1,16):\n",
        "    # Set number of neighbours to ii\n",
        "    KNN = KNeighborsClassifier(n_neighbors=ii)\n",
        "    # Training or fitting the model with the data\n",
        "    KNN.fit(x_train_scale,y_train)\n",
        "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
        "    accuracy.append(KNN.score(x_test_scale,y_test))\n",
        "    # Append the number of neighbours to a list\n",
        "    num_neigh.append(ii)\n",
        "\n",
        "print(accuracy)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9210526315789473, 0.8947368421052632, 0.9473684210526315, 0.9473684210526315, 0.9473684210526315, 0.9210526315789473, 0.9210526315789473, 0.9473684210526315, 0.8947368421052632, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riI5_yY4t8TG"
      },
      "source": [
        "Let us plot the accuracy values on the graph to help us determine the optimal number of neighbours. Try the code below! Remember to `import matplotlib.pyplot as plt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahgOfWP2t8TH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "bc386ee5-e93e-4513-fb7f-1049bc12df85"
      },
      "source": [
        "plt.scatter(num_neigh,accuracy)\n",
        "plt.xlabel('Number of neighbours')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show();"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bfbHcFUt8TK"
      },
      "source": [
        "From the graph above, which will be the optimal number of neighbours to use? Explain your answer.\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2idKhvjt8TL"
      },
      "source": [
        "# 3, because it is a odd number and it has a high acc. It also requires the least amount of time to complete."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY6ESCk-t8TQ"
      },
      "source": [
        "## 2.2 Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz_tic2Tt8TR"
      },
      "source": [
        "It is also possible for a decision tree to underfit or overfit.\n",
        "\n",
        "For example, if the tree only has 1 decision point then it is likely for the tree to underfit. However, if the tree has multiple decision points, then it is possible for the tree to overfit. As such, the deeper the tree, the more likely it is for the tree to overfit. Based on your understanding of overfitting and underfitting, decide which trees (shown below) will be likely to overfit or underfit the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu5iAMNBt8TT"
      },
      "source": [
        "![Overfit](https://jotterbach.github.io/static/d2dc5f7eb2d525500c8e06241769651e/34ea8/decision_tree_overfit_branching.png)\n",
        "\n",
        "Please refer to \n",
        "\"/content/Intel_AI4Y/My Drive/Intel_AI4Y_Colab/Module_18/resources/dt1.jpg\"\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7vDfoqPt8TU"
      },
      "source": [
        "# blue will underfit\n",
        "# orange will overfit(noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-nSDvtAt8TY"
      },
      "source": [
        "![Underfit](https://miro.medium.com/max/6810/1*1tGLoeGg4cDwQXSLSgD5Zg.png)\n",
        "\n",
        "Please refer to \n",
        "\"/content/Intel_AI4Y/My Drive/Intel_AI4Y_Colab/Module_18/resources/dt2.jpg\"\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ngf3jyt8TZ"
      },
      "source": [
        "#your answer here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MevHzmwQt8Tc"
      },
      "source": [
        "Additionally, another way to control for overfitting or underfitting is based on the minimum number of samples that are at a decision point before a split is conducted. For example, if we have a decision point in the tree that is based on weather and there are 50 different points either consisting of sunny days or rainy days, it will be obvious that we should split the data at that decision point as there are quite a few samples or data points. However, if we only have 2 data points at that weather decision point, then it may not be necessary to split them based on weather as it may lead to overfitting. Thus, we can also use the number of samples at a decision point to control the fit.\n",
        "\n",
        "You can read this [article](https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3) to understand more on how to control for overfitting and underfitting in a decision tree. What are the other variables that we can use to control the fit in a decision tree?\n",
        "\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrhoBzBt8Td"
      },
      "source": [
        "'''criterion{“gini”, “entropy”}, default=”gini”\n",
        "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.'''\n",
        "\n",
        "'''splitter{“best”, “random”}, default=”best”\n",
        "The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.'''\n",
        "\n",
        "'''min_samples_splitint or float, default=2\n",
        "The minimum number of samples required to split an internal node:'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWbrvCE-t8Tg"
      },
      "source": [
        "Let us try to find the best set of parameters to allow the decision tree to have a good fit on the Iris Flower dataset. We can use the same splitted datasets from the earlier exercise above. Try the code below! The variable that we are using to control the fit in the tree is known as max_depth. This refers to the maximum depth of the tree. The deeper the tree, the more likely it is for the tree to overfit. Remember to import tree from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_jH1-yXt8Th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cb9aad-73c9-4752-b6f6-becf27ade300"
      },
      "source": [
        "# Create an empty list to store the accuracy and the best tested parameter for each decision tree\n",
        "accuracy = []\n",
        "depth = []\n",
        "\n",
        "# Use ii to cycle through values 1 to 9. This will be the max_depth value for the decision tree. \n",
        "for ii in range(1,10):\n",
        "    # Set max_depth to ii\n",
        "    dt = tree.DecisionTreeClassifier(max_depth=ii)\n",
        "    # Training or fitting the model with the data\n",
        "    dt.fit(x_train_scale,y_train)\n",
        "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
        "    accuracy.append(dt.score(x_test_scale,y_test))\n",
        "    # Append the max_depth values to a list\n",
        "    depth.append(ii)\n",
        "\n",
        "print(accuracy)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5526315789473685, 0.9473684210526315, 0.9473684210526315, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-eq-Ywt8Tl"
      },
      "source": [
        "Can you plot the accuracy values against the `max_depth` values in a graph? You can refer to the earlier graph for referrence.\n",
        "\n",
        "<font color=red>Hints:</font> \n",
        "*   Refer to Module 13 Assignment 2 \"Data Visualization\" or Module 16 Assignment 2 \"Basic_data_processing_and_visualisation\" on Scatter plot\n",
        "*   `x` => `Max_Depth`\n",
        "*   `y` => `Accuracy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqpEUxcYt8Tm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "596e98e9-75e7-44ab-b716-ab28d8d85c88"
      },
      "source": [
        "plt.scatter(depth,accuracy)\n",
        "plt.xlabel('Max_Depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show();"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69TuTrb5t8To"
      },
      "source": [
        "From the graph, which will be the recommended `max_depth` value?\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t82bvsXut8Tp"
      },
      "source": [
        "# 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czz5d__vt8Tr"
      },
      "source": [
        "If you recall, the minimum number of samples at a decision point can also be used to prevent overfitting or underfitting. In the decision tree algorithm, this value is controlled by `min_samples_split`. Copy the code above and modify it to find the best `min_samples_split` value. You can use the range between `2` and `15`. Plot the accuracy values for easy visualisation as well.\n",
        "\n",
        "<font color=red>Hint:</font>  similar to above 2 sections of code but use `min_samples_split`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCS1h8A5t8Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfa2b49-f204-43ee-ccf0-ec429b5e0c5f"
      },
      "source": [
        "# Create an empty list to store the accuracy and the best tested parameter for each decision tree\n",
        "accuracy = []\n",
        "depth = []\n",
        "\n",
        "# Use ii to cycle through values 1 to 9. This will be the max_depth value for the decision tree. \n",
        "for ii in range(1,10):\n",
        "    # Set max_depth to ii\n",
        "    dt = tree.DecisionTreeClassifier(min_samples_split=2)\n",
        "    # Training or fitting the model with the data\n",
        "    dt.fit(x_train_scale,y_train)\n",
        "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
        "    accuracy.append(dt.score(x_test_scale,y_test))\n",
        "    # Append the max_depth values to a list\n",
        "    depth.append(ii)\n",
        "\n",
        "print(accuracy)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473, 0.9210526315789473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "S6l8b-HFUc3y",
        "outputId": "95a0cc57-f001-48c5-8a61-c11cd35fa631"
      },
      "source": [
        "plt.scatter(depth,accuracy)\n",
        "plt.xlabel('min_samples_split')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show();"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxO3LgUit8Tu"
      },
      "source": [
        "From your graph, which will be the best `min_samples_split` value? Would you choose the lowest value with the highest accuracy?\n",
        "\n",
        "\n",
        "<font color=red>Your answer:</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Ta1zost8Tv"
      },
      "source": [
        "# 1. 5, becuase min_samples_split is used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. \n",
        "#Too high values can also lead to under-fitting hence depending on the level of underfitting or overfitting"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}