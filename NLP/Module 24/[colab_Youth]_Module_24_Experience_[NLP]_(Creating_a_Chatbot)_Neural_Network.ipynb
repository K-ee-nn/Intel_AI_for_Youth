{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "[colab_Youth]_Module_24_Experience_[NLP]_(Creating_a_Chatbot)_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqZ0OF5rYv1B"
      },
      "source": [
        "# NLP Lesson Map: NLP Process\n",
        "\n",
        "<font color=red>Red </font> highlighted is the topic covered for this lesson\n",
        "\n",
        "1.\tObtain Text\n",
        "> *\tFrom NTLK\n",
        "> *\tFrom website\n",
        "> *\tFrom CSV\n",
        "2.\t<font color=red>Tokens</font>\n",
        "> *\tSentence Segmentation\n",
        "> *\tTokenization\n",
        "> *\t<font color=red>Remove stopwords, special characters, numbers\n",
        "> *\tConverting text to a common case</font>\n",
        "> *\tStemming & Lemmatization\n",
        "3.\tNumbers\n",
        "> *\tCreate a Dictionary\n",
        "> *\t<font color=red>Create Document Vectors = Bag of Words = Term Frequency (tf)  = number of times that each word occurs per document</font>\n",
        "> *\tidf\n",
        "> *\ttf-idf\n",
        "4.\t<font color=red>AI Models</font>\n",
        "> * Logistic Regression\n",
        "> *\tCosine Similarity\n",
        "> *\t<font color=red>Neural Network</font>\n",
        "5.\t<font color=red>NLP Applications</font>\n",
        "> * Classification\n",
        "> *\tSentiment Analysis\n",
        "> *\t<font color=red>Chatbot</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCWNzwSBdqZy"
      },
      "source": [
        "# Build a Chatbot with Neural Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejgp0xs-dqZ1"
      },
      "source": [
        "We've discovered how to build a chatbot with cosine similarity. Now, let's explore how we might build one with neural network!\n",
        "\n",
        "We will create our training data, train a neural network with them, then use the trained model to make our chatbot. \n",
        "\n",
        "First, we will install required libraries. Uncomment the few blocks below only if you do not have the libraries installed. \n",
        "\n",
        "<font color=red>Note:</font> \n",
        "* Colab has all these libraries installed.  Hence, no need to uncomment.  This is for your reference if you are running these code on your PC.\n",
        "\n",
        "* This lab is adapted from the below link. Please to refer to this link for further info or **better understanding**.\n",
        " \n",
        ">> https://blog.eduonix.com/internet-of-things/simple-nlp-based-chatbot-python/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLLoeKxdqZ2"
      },
      "source": [
        "#!pip install numpy scipy\n",
        "#!pip install scikit-learn\n",
        "#!pip install pillow\n",
        "#!pip install h5py"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ndYjY0HidqZ_"
      },
      "source": [
        "#!pip install tensorflow"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tt3U34tdqaD"
      },
      "source": [
        "#!pip install tensorflow-gpu"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeTqM6S5dqaG"
      },
      "source": [
        "#!pip install keras"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBVrDzS3dqaO"
      },
      "source": [
        "# 1. Install Libraries\n",
        "\n",
        "Firstly, we will install libraries needed for this neural network powered chatbot. \n",
        "Keras is a machine learning library which utilizes tensorflow (another lower level machine learning library) at the backend. This makes it easier for us to deploy deep neural network for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on3TllqMdqaQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense\n",
        " \n",
        "from numpy import argmax\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sog3kpWYdqaV"
      },
      "source": [
        "# 2. Input training data\n",
        "\n",
        "We will first include the following training data for our chatbot:\n",
        "1. `X` represent the different possible inputs that users might enter\n",
        "2. `Y` represent the intent of the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhWPKQpcdqaW"
      },
      "source": [
        "X = ['Hi',\n",
        "     'Hello',\n",
        "     'How are you?',\n",
        "     'I am making',\n",
        "     'making',\n",
        "     'working',\n",
        "     'studying',\n",
        "     'see you later',\n",
        "     'bye',\n",
        "     'goodbye']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT3ku6e1dqaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd39152-d635-4902-c6ec-b99a33258906"
      },
      "source": [
        "print(len(X))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7G8c935dqaq"
      },
      "source": [
        "Y = ['greeting',\n",
        "     'greeting',\n",
        "     'greeting',\n",
        "     'busy',\n",
        "     'busy',\n",
        "     'busy',\n",
        "     'busy',\n",
        "     'bye',\n",
        "     'bye',\n",
        "     'bye']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk0c6zZvdqau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200a258d-b2d6-436e-8df4-4331c9be87f5"
      },
      "source": [
        "print(len(Y))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfopFSGKdqa3"
      },
      "source": [
        "Notice that there are several different sentences that have similar intent. Here, we are only having 3 intents, but you can add as many as you want for your project!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZuEG_c-dqa4"
      },
      "source": [
        "This is the way our chatbot will work:\n",
        "1. From the input sentence, we will identify the intent using our trained AI model.\n",
        "2. For each intent, we have a prepared response. \n",
        "\n",
        "For example, if we identify that the intent of the input is for a greeting, we might ask the chatbot to reply with a greeting as well, something like 'hi' or 'how are you doing?'\n",
        "\n",
        "We will use machine learning to create a model that can classify input sentence into different intents. \n",
        "We make it as follows:\n",
        "\n",
        "1. We create a training data (`X` and `Y` above) which contains a list of sentences and their intents.\n",
        "2. Use the training data to train a classifier. \n",
        "3. Vectorize input sentences and use classifier to determine intent. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WN4JwGvdqa5"
      },
      "source": [
        "# 3. Text processing\n",
        "\n",
        "As usual, we will start with text processing. Do you remember the process?\n",
        "\n",
        "## 3.1 Remove non alphanumeric characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkopNyMMdqa6"
      },
      "source": [
        "def remove_non_alpha_numeric_characters(sentence):\n",
        "    new_sentence = ''\n",
        "    for alphabet in sentence:\n",
        "        if alphabet.isalpha() or alphabet == ' ':\n",
        "            new_sentence += alphabet\n",
        "    return new_sentence"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRCWjplpdqa9"
      },
      "source": [
        "def preprocess_data(X):\n",
        "    X = [data_point.lower() for data_point in X]\n",
        "    X = [remove_non_alpha_numeric_characters(\n",
        "        sentence) for sentence in X]\n",
        "    X = [data_point.strip() for data_point in X]\n",
        "    X = [re.sub(' +', ' ',\n",
        "                data_point) for data_point in X]\n",
        "    return X"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKMfh2MVdqbB"
      },
      "source": [
        "X = preprocess_data(X)\n",
        "\n",
        "vocabulary = set()\n",
        "for data_point in X:\n",
        "    for word in data_point.split(' '):\n",
        "        vocabulary.add(word)\n",
        "\n",
        "vocabulary = list(vocabulary)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkOYFtNdqbE"
      },
      "source": [
        "## Create document vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyJ2boXPdqbF"
      },
      "source": [
        "X_encoded = []\n",
        "\n",
        "def encode_sentence(sentence):\n",
        "    sentence = preprocess_data([sentence])[0]\n",
        "    sentence_encoded = [0] * len(vocabulary)\n",
        "    for i in range(len(vocabulary)):\n",
        "        if vocabulary[i] in sentence.split(' '):\n",
        "            sentence_encoded[i] = 1\n",
        "    return sentence_encoded\n",
        "\n",
        "X_encoded = [encode_sentence(sentence) for sentence in X]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oQRZcGGdqbJ"
      },
      "source": [
        "classes = list(set(Y))\n",
        "\n",
        "Y_encoded = []\n",
        "for data_point in Y:\n",
        "    data_point_encoded = [0] * len(classes)\n",
        "    for i in range(len(classes)):\n",
        "        if classes[i] == data_point:\n",
        "            data_point_encoded[i] = 1\n",
        "    Y_encoded.append(data_point_encoded)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruQ16rSBdqbN"
      },
      "source": [
        "# 4. Create training data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiXSJeg2dqbO"
      },
      "source": [
        "X_train = X_encoded\n",
        "y_train = Y_encoded\n",
        "X_test = X_encoded\n",
        "y_test = Y_encoded"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvWZod36dqbS"
      },
      "source": [
        "Print and check the data you are using for training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh1lIh4IdqbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8fd2fa-08f0-4020-a82b-961f7bb1ca59"
      },
      "source": [
        "print (y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0PPHHOEdqbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61551602-e766-4c98-d303-4bcd8e1fce7f"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n",
            "10\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Px5-hCZXdqbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bb691e-959d-42ec-8d5c-b7f7d2e135bd"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 1, 0],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [0, 0, 1],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0],\n",
              " [1, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKTA60hFdqbc"
      },
      "source": [
        "What does `y_train` represent? Do you understand the array shown above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqlAGO27dqbd"
      },
      "source": [
        "# 5. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbl-Sf1ddqbe"
      },
      "source": [
        "Now we will use the training data to train our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnUSTO9mdqbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0906f5d0-c658-4da8-f808-ca7dec6c5302"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=64, activation='sigmoid',input_dim=len(X_train[0])))\n",
        "\n",
        "model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
        "\n",
        "model.compile(loss=categorical_crossentropy,optimizer=SGD(lr=0.01,momentum=0.9, nesterov=True))\n",
        "\n",
        "model.fit(np.array(X_train), np.array(y_train), epochs=100, batch_size=16)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 1.2313\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2091\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1834\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1591\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1398\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1268\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1202\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1184\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1196\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1218\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1234\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1236\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1219\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1186\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1142\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1092\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1042\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0997\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0958\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0926\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0900\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0878\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0857\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0837\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0815\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0791\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0765\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0738\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0710\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0682\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0655\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0628\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0602\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0577\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0552\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0528\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0503\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0478\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0454\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0429\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0404\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0379\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0354\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0329\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0304\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0280\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0255\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0231\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0206\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0182\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0158\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0133\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0109\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0085\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0061\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0036\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0012\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9988\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9964\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9940\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9916\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9892\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9868\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9844\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9820\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9796\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9772\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9748\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9724\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9700\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9676\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9652\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9628\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9604\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9580\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9556\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9532\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9508\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9484\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9460\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9436\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9412\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9388\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9364\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9340\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9316\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9291\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9267\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9243\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9219\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9195\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9170\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9146\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9122\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9098\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9073\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9049\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9024\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe333a9e50>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApEN2ry0dqbi"
      },
      "source": [
        "## List down predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuwVBTXLdqbj"
      },
      "source": [
        "predictions = [argmax(pred) for pred in model.predict(np.array(X_test))]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weV5kIBAdqbm"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxffRqq3dqbm"
      },
      "source": [
        "Let's evaluate our model now. We will compare the prediction made by the model and our test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akIIApp5dqbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5218ebb-e104-4281-9f90-e8ccda68757a"
      },
      "source": [
        "correct = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == argmax(y_test[i]):\n",
        "        correct += 1\n",
        "\n",
        "print (\"Correct:\", correct)\n",
        "print (\"Total:\", len(predictions))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct: 8\n",
            "Total: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK68yiWDdqbq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfG5pglEdqbr"
      },
      "source": [
        "# Testing the chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UoYXDa7dqbr"
      },
      "source": [
        "Let's test the chatbot now! We will input a sentence, and then see what class is predicted by the neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "isbEv9rCdqbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "a0b25a37-b56e-4775-b00d-757fac531dfd"
      },
      "source": [
        "while True:\n",
        "    print (\"Enter a sentence\")\n",
        "    sentence = input()\n",
        "    prediction= model.predict(np.array([encode_sentence(sentence)]))\n",
        "    print (classes[argmax(prediction)])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence\n",
            "goodbye\n",
            "busy\n",
            "Enter a sentence\n",
            "hi\n",
            "busy\n",
            "Enter a sentence\n",
            "busy\n",
            "busy\n",
            "Enter a sentence\n",
            "bye\n",
            "busy\n",
            "Enter a sentence\n",
            "hello\n",
            "greeting\n",
            "Enter a sentence\n",
            "how are you\n",
            "greeting\n",
            "Enter a sentence\n",
            "bye\n",
            "busy\n",
            "Enter a sentence\n",
            "bye\n",
            "busy\n",
            "Enter a sentence\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bc094bc758c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px2w4yAXdqbv"
      },
      "source": [
        "Realize that you can't stop the chatbot? You'll have to add the exit command later (see the previous notebook to find out how to do it. \n",
        "\n",
        "For now, simply press the stop button (interrupt button) above to stop the chatbot. \n",
        "\n",
        "Try it! press the stop button, and try typing something onto the box. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnJngfeJdqbw"
      },
      "source": [
        "# <font color=red>Challenge</font> \n",
        "\n",
        "We have successfully use neural network to map our input to conversation intent. \n",
        "Your challenge is to link the conversation intent to a particular response that the chatbot will say. \n",
        "For example, if the conversation intent is 'greeting', get your chatbot to say a greeting as well!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAxYTVczdqbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7cefed-7bc1-4f0e-8151-357c4cd9eac9"
      },
      "source": [
        "import random\n",
        "greeting_responses = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\", \"Hi there sir!\"]\n",
        "busy_responses = ['Sorry to disturb you!', 'Ok I will talk to you later then', 'ok sorry', 'ok', 'K']\n",
        "bye_responses = ['Had a great time chatting with you!', 'Bye bye, have a great time']\n",
        "\n",
        "# Let's chat for 4 lines\n",
        "for line in range(4):\n",
        "  print('Enter a sentence')\n",
        "  sentence = input()\n",
        "  prediction = model.predict(np.array([encode_sentence(sentence)]))\n",
        "  if classes[argmax(prediction)] == 'greeting':\n",
        "    print(\"Bot: {}\".format(random.choice(greeting_responses)))\n",
        "  if classes[argmax(prediction)] == 'busy':\n",
        "     print(\"Bot: {}\".format(random.choice(busy_responses)))\n",
        "  if classes[argmax(prediction)] == 'bye':\n",
        "     print(\"Bot: {}\".format(random.choice(bye_responses)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence\n",
            "hi\n",
            "Bot: hello\n",
            "Enter a sentence\n",
            "studying\n",
            "Bot: Sorry to disturb you!\n",
            "Enter a sentence\n",
            "see you later\n",
            "Bot: Bye bye, have a great time\n",
            "Enter a sentence\n",
            "working\n",
            "Bot: ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlRVjf8Ndqb1"
      },
      "source": [
        "### Great job! You've successfully created a simple chatbot with neural network! How might you improve the chatbot?\n",
        "You can improve the chatbot by:\n",
        "- Adding more training data\n",
        "- Adding more intent\n",
        "- Focusing on a particular topic and train the chatbot with many training data in that topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNaTHUP5dqb2"
      },
      "source": [
        "### Resource:\n",
        "https://blog.eduonix.com/internet-of-things/simple-nlp-based-chatbot-python/"
      ]
    }
  ]
}